# import pandas as pd
# from pathlib import Path

# # ================= é…ç½®åŒºåŸŸ =================
# DATASET_PATH = "/home/openpi/data/data_converted/exp19_lerobot_autoPut_data_0113night_224_224/xarm_autoPut_pi05_dataset"
# TARGET_EPISODE_IDX = 0
# # ===========================================

# def export_raw_data():
#     base_path = Path(DATASET_PATH)
#     # æ ¸å¿ƒä¿®æ”¹ï¼šæ ¹æ®ä½ çš„æˆªå›¾ï¼Œparquet åœ¨ data/chunk-000 ä¸‹
#     data_dir = base_path / "data" / "chunk-000"
    
#     print(f"ğŸ“‚ æ­£åœ¨æ‰«æç›®å½•: {data_dir}")

#     # 1. æŸ¥æ‰¾æ‰€æœ‰çš„ parquet æ–‡ä»¶
#     parquet_files = sorted(list(data_dir.glob("episode_*.parquet")))
    
#     if not parquet_files:
#         print(f"âŒ é”™è¯¯ï¼šåœ¨ {data_dir} æ‰¾ä¸åˆ° episode_xxxxxx.parquet æ–‡ä»¶")
#         return

#     # 2. æ‰¾åˆ°ç›®æ ‡ episode çš„æ–‡ä»¶
#     # æ ¼å¼ä¸º episode_000000.parquetï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æŠŠæ•°å­—è¡¥é½åˆ°6ä½
#     target_filename = f"episode_{TARGET_EPISODE_IDX:06d}.parquet"
#     target_file = data_dir / target_filename

#     if not target_file.exists():
#         print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç›®æ ‡æ–‡ä»¶ {target_filename}")
#         print(f"å½“å‰ç›®å½•ä¸‹å­˜åœ¨çš„æ–‡ä»¶ç¤ºä¾‹: {[f.name for f in parquet_files[:3]]}")
#         return

#     print(f"ğŸ“– æ­£åœ¨è¯»å–: {target_filename}")
#     df = pd.read_parquet(target_file)

#     # 3. å¯¼å‡º CSV
#     output_filename = f"episode_{TARGET_EPISODE_IDX}_full_data.csv"
#     # ä¿å­˜åˆ°å½“å‰è„šæœ¬è¿è¡Œçš„ç›®å½•
#     # --- æ–°å¢ï¼šé™åˆ¶æµ®ç‚¹æ•°ç²¾åº¦ ---
#     # ä»…é’ˆå¯¹æµ®ç‚¹æ•°ç±»å‹çš„åˆ—è¿›è¡Œå››èˆäº”å…¥ï¼Œä¿ç•™ 6 ä½å°æ•°
#     df = df.round(4) 
#     # --------------------------

#     # ä¿å­˜åˆ°å½“å‰è„šæœ¬è¿è¡Œçš„ç›®å½•
#     df.to_csv(output_filename, index=False)
    
#     print(f"\nâœ… å¯¼å‡ºæˆåŠŸï¼")
#     print(f"ğŸ“ ä¿å­˜ä½ç½®: {Path.cwd() / output_filename}")
    
#     # 4. æ•°æ®é¢„è§ˆ
#     print("\n--- æ ¸å¿ƒæ•°æ®é¢„è§ˆ (å‰5è¡Œ) ---")
#     # è‡ªåŠ¨è¯†åˆ«åˆ—åï¼ˆOpenPI æ ¼å¼é€šå¸¸åŒ…å« state, action ç­‰ï¼‰
#     available_cols = df.columns.tolist()
#     # æŒ‘é€‰ä¸€äº›å…³é”®åˆ—å±•ç¤ºï¼Œé˜²æ­¢åˆ—å¤ªå¤šåˆ·å±
#     preview_cols = [c for c in available_cols if 'state' in c or 'action' in c or 'index' in c][:8]
#     print(df[preview_cols].head().to_string(index=False))

# if __name__ == "__main__":
#     export_raw_data()

import pandas as pd
from pathlib import Path
import json
import numpy as np

# ================= é…ç½®åŒºåŸŸ =================
DATASET_PATH = "/home/openpi/data/data_converted/exp1_lerobot_autoPut_data_0128night_224_224/xarm_autoPut_pi05_dataset"
TARGET_EPISODE_IDX = 0
# ===========================================

def export_raw_data():
    base_path = Path(DATASET_PATH)
    data_dir = base_path / "data" / "chunk-000"
    
    target_filename = f"episode_{TARGET_EPISODE_IDX:06d}.parquet"
    target_file = data_dir / target_filename

    if not target_file.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {target_file}")
        return

    print(f"ğŸ“– æ­£åœ¨è¯»å–: {target_filename}")
    df = pd.read_parquet(target_file)

    # --- æ ¸å¿ƒä¿®å¤ï¼šç§»é™¤å›¾åƒåˆ— ---
    # å›¾åƒæ•°æ®é€šå¸¸å¾ˆå¤§ä¸”æ˜¯äºŒè¿›åˆ¶ï¼Œæ— æ³•ç›´æ¥è½¬ JSON
    cols_to_keep = [c for c in df.columns if 'image' not in c.lower()]
    df_numeric = df[cols_to_keep].copy()
    print(f"âœ‚ï¸ å·²è¿‡æ»¤å›¾åƒåˆ—ï¼Œä¿ç•™å­—æ®µ: {cols_to_keep}")

    # --- ç²¾åº¦å¤„ç†ï¼šç¼©å‡è‡³ 4 ä½å°æ•° ---
    def round_nested(val):
        if isinstance(val, (list, np.ndarray)):
            return [round(float(x), 8) for x in val]
        elif isinstance(val, (float, np.float32, np.float64)):
            return round(float(val), 8)
        return val

    # ä½¿ç”¨æ–°çš„ .map() ä»£æ›¿è¢«å¼ƒç”¨çš„ .applymap()
    df_numeric = df_numeric.map(round_nested)

    # --- å¯¼å‡ºä¸º JSON ---
    output_filename = f"episode_{TARGET_EPISODE_IDX}_numeric_data.json"
    
    try:
        df_numeric.to_json(output_filename, orient='records', force_ascii=False, indent=2)
        print(f"\nâœ… å¯¼å‡ºæˆåŠŸï¼")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {Path.cwd() / output_filename}")
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    # --- é¢„è§ˆç¬¬ä¸€å¸§ ---
    print("\n--- ç¬¬ä¸€å¸§æ•°å€¼æ•°æ®é¢„è§ˆ ---")
    print(json.dumps(df_numeric.iloc[0].to_dict(), indent=4))

if __name__ == "__main__":
    export_raw_data()