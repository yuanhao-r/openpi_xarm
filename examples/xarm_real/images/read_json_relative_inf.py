import time
import cv2
import numpy as np
import sys
import os
import termios
import select
import random
import threading
from pathlib import Path
from scipy.spatial import ConvexHull
from xarm.wrapper import XArmAPI
import json

# OpenPI ä¾èµ–
current_dir = os.path.dirname(os.path.abspath(__file__))
openpi_client_path = os.path.join(current_dir, "../../../packages/openpi-client/src")
sys.path.append("/home/openpi/src")
sys.path.append(os.path.abspath(openpi_client_path))

from openpi.training import config as _config
from openpi.policies import policy_config
from openpi_client import image_tools

import matplotlib
matplotlib.use('Agg') # è®¾ç½®åç«¯ä¸ºéäº¤äº’å¼ï¼ŒDocker ä¸“ç”¨
import matplotlib.pyplot as plt

# -----------------------------------------------------------------------------
# 1. é…ç½®åŒºåŸŸ (ä¿æŒ Code A åŸæ ·)
# -----------------------------------------------------------------------------
ROBOT_IP = "192.168.1.232"
CONFIG_NAME = "pi05_xarm_1212_night"
CHECKPOINT_DIR = "/home/openpi/checkpoints/exp23/24000"
VIS_SAVE_DIR = "/home/openpi/examples/xarm_real/images"
# RESULT_IMG_NAME = "0121mafternoon_cloudyDay_exp22_36000_test20_components E23.png"
# TASK_PROMOT = "pick up the industrial components"
TASK_PROMOT = "pick up the small upright valve "
SELECTED_TASK = "D"  
# --- ä»»åŠ¡é…ç½®å­—å…¸ ---
TASK_CONFIGS = {
    "A": {
        "prompt": "pick up the hollow rectangular housing",
        "z": -65
    },
    "B": {
        "prompt": "pick up the silver metal cylinder",
        "z": -65
    },
    "C": {
        "prompt": "pick up the small upright valve",
        "z": -79
    },
    "D": {
        "prompt": "pick up the flat triangular plate",
        "z": -65
    },
    "E": {
        "prompt": "pick up the silver metal cylinder",
        "z": -65
    },
    "F": {
        "prompt": "pick up the flat circular plate",
        "z": -103
    },
    "G": {
        "prompt": "pick up the flat circular plate",
        "z": -109
    }
}
# è·å–å½“å‰ä»»åŠ¡çš„é…ç½®
current_config = TASK_CONFIGS[SELECTED_TASK]
OBJECT_Z = current_config["z"]
# è®¾ç½®æç¤ºè¯
TASK_PROMOT = current_config["prompt"]
# åŸºç¡€åæ ‡ (X, Y, Roll, Pitch, Yaw)
_base_x = 554.626923
_base_y = 361.343277
_base_r = 3.12897
_base_p = 0.012689
_base_yw = -1.01436
# ç»„è£… POS_A (åŠ¨æ€å¡«å…¥å¯¹åº”çš„ Z å€¼)
POS_A = [_base_x, _base_y, current_config["z"], _base_r, _base_p, _base_yw]
# è‡ªåŠ¨ç”Ÿæˆç»“æœå›¾ç‰‡æ–‡ä»¶å (é¿å…æ‰‹åŠ¨æ”¹å)
RESULT_IMG_NAME = f"0127afternoon_cloudyDay_exp23_24000_test2_components_{SELECTED_TASK}.png"
print(f">>> å½“å‰ä»»åŠ¡: [{SELECTED_TASK}]")
print(f">>> Prompt: {TASK_PROMOT}")
print(f">>> POS_A Z-height: {POS_A[2]}")
#æŒ‡å®šè¦è¯»å–çš„ç‚¹ä½æ–‡ä»¶
POINTS_FILE = os.path.join(VIS_SAVE_DIR, "test_points.json")
RESUME_TESTING = True # å¼€å…³ï¼šæ˜¯å¦å¼€å¯æ–­ç‚¹ç»­æµ‹
PROGRESS_FILE = os.path.join(VIS_SAVE_DIR, "test_progress.json") # è¿›åº¦æ–‡ä»¶è·¯å¾„
CAMERAS = {
    "cam_left_wrist": "/dev/cam_left_wrist",
    "cam_right_wrist": "/dev/cam_right_wrist"
}
CROP_CONFIGS = {
    "cam_left_wrist": (118, 60, 357, 420),
    "cam_right_wrist": (136, 57, 349, 412)
}

CONTROL_FREQ = 10 
EXECUTE_STEPS = 2
JOINT_LIMITS = [
    (-6.2, 6.2), (-2.0, 2.0), (-2.9, 2.9), 
    (-3.1, 3.1), (-1.6, 1.8), (-6.2, 6.2)
]

# HOME_POS = [486.626923, 297.343277, 30.431152, 3.12897, 0.012689, -1.01436]
# POS_A = [486.626923, 297.343277, -65, 3.12897, 0.012689, -1.01436]
HOME_POS = [554.626923, 361.343277, 30.431152, 3.12897, 0.012689, -1.01436]
# POS_A = [554.626923, 361.343277, -79, 3.12897, 0.012689, -1.01436]
MIN_SAFE_Z = -119
# HOME_POS = [539.120605, 17.047951, 100-59.568863, 3.12897, 0.012689, -1.01436]
# POS_A = [539.120605, 17.047951, -79.568863, 3.12897, 0.012689, -1.01436]
# MIN_SAFE_Z = -99
SLOW_DOWN_FACTOR = 2.0  
INTERPOLATION_FREQ = 100.0 

# exp9 boundary
BOUNDARY_POINTS_2D = np.array([
    [528.6, 126.5],
    [745.0, 250.2],
    [501.9, 539.4],
    [338.1, 425.0],
])
# è®¡ç®—å®½æ¾è¾¹ç•Œ (Relaxed Boundary)
# ä»¥ä¸­å¿ƒç‚¹ä¸ºåŸºå‡†ï¼Œå‘å¤–æ‰©å¼  1.1 å€ (å³å…è®¸è¶…å‡º 10%)
# 1.15 è¡¨ç¤ºå…è®¸å‘å¤–æ‰© 15% çš„èŒƒå›´ï¼Œä½ å¯ä»¥æ ¹æ®å®é™…æ¡Œå­å¤§å°è°ƒæ•´è¿™ä¸ªç³»æ•°
_center_point = np.mean(BOUNDARY_POINTS_2D, axis=0)
BOUNDARY_EXPANDED = _center_point + (BOUNDARY_POINTS_2D - _center_point) * 1.15

FIXED_Z = POS_A[2]
FIXED_ROLL = POS_A[3]
FIXED_PITCH = POS_A[4]
BASE_YAW = POS_A[5]
YAW_RANDOM_RANGE = (-np.pi/6, np.pi/6)


class MetricsRecorder:
    def __init__(self):
        self.episode_metrics = []
        self.current_episode = {}
        
    def start_episode(self, start_pose_abs, ground_truth_pose):
        """
        å¼€å§‹è®°å½•ä¸€è½®æµ‹è¯•
        :param start_pose_abs: æœºæ¢°è‡‚èµ·å§‹çš„ç»å¯¹åæ ‡ [x, y, z, r, p, y] (å•ä½: ç±³)
        :param ground_truth_pose: JSONæ–‡ä»¶é‡Œçš„ç›®æ ‡åæ ‡ [x, y, z, r, p, y] (å•ä½: æ¯«ç±³)
        """
        self.current_episode = {
            "start_time": time.time(),
            # ç»Ÿä¸€è½¬æ¢ä¸ºæ¯«ç±³ (mm) å­˜å‚¨ï¼Œæ–¹ä¾¿è®¡ç®—
            "start_pose": np.array(start_pose_abs) * 1000.0, 
            "ground_truth_pose": np.array(ground_truth_pose), # å‡è®¾ JSON é‡Œæ˜¯ mm
            "trajectory": [], 
            "success": False,
            "steps": 0
        }
        # è®°å½•èµ·ç‚¹
        self.current_episode["trajectory"].append(self.current_episode["start_pose"][:3])
        # =======================================================
        # åˆå§‹åŒ– final_pos_mm å’Œ final_rpy_rad
        # å³ä½¿ä¸€æ­¥æ²¡èµ°ï¼Œå½“å‰çš„æœ€ç»ˆä½ç½®å°±æ˜¯èµ·å§‹ä½ç½®
        # =======================================================
        self.current_episode["final_pos_mm"] = self.current_episode["start_pose"][:3]
        self.current_episode["final_rpy_rad"] = start_pose_abs[3:]
    def step(self, current_pose_abs):
        """è®°å½•æ¯ä¸€æ­¥çš„å®é™…ä½ç½® (è¾“å…¥å•ä½: ç±³)"""
        # è½¬ä¸º mm å­˜å‚¨
        pos_mm = np.array(current_pose_abs[:3]) * 1000.0
        self.current_episode["trajectory"].append(pos_mm)
        self.current_episode["steps"] += 1
        
        # å®æ—¶æ›´æ–°æœ€ç»ˆä½å§¿ (ä»¥æœ€åä¸€æ­¥ä¸ºå‡†)
        # åŒæ—¶è®°å½•æœ€åä¸€æ­¥çš„æ—‹è½¬ (Roll, Pitch, Yaw) ç”¨äºç®—è§’åº¦è¯¯å·®
        self.current_episode["final_full_pose"] = np.array(current_pose_abs) * 1000.0 # [x,y,z, r,p,y]
        # æ³¨æ„ï¼šr,p,y è¿™é‡Œä¹Ÿè¢«ä¹˜äº†1000ï¼Œåé¢è®¡ç®—æ—¶è¦è¿˜åŸå›å»ï¼Œæˆ–è€…åˆ†å¼€å¤„ç†
        # ä¿®æ­£ï¼šæˆ‘ä»¬åˆ†å¼€å­˜
        self.current_episode["final_pos_mm"] = pos_mm
        self.current_episode["final_rpy_rad"] = current_pose_abs[3:]

    def end_episode(self, success, close_gripper_time):
        # self.current_episode["end_time"] = time.time()
        self.current_episode["end_time"] = close_gripper_time
        self.current_episode["success"] = success
        
        # è®¡ç®—è¯¥è½®æŒ‡æ ‡
        metrics = self._calculate_single_metrics(self.current_episode)
        self.episode_metrics.append(metrics)
        return metrics

    def _calculate_single_metrics(self, data):
        # 1. è€—æ—¶
        duration = data["end_time"] - data["start_time"]
        
        # 2. è½¨è¿¹å¹³æ»‘åº¦ (Jerk)
        traj = np.array(data["trajectory"]) # (T, 3) mm
        if len(traj) > 3:
            vel = np.diff(traj, axis=0)
            acc = np.diff(vel, axis=0)
            jerk = np.diff(acc, axis=0)
            avg_jerk = np.mean(np.linalg.norm(jerk, axis=1))
        else:
            avg_jerk = 0.0

        # 3. æ­¥æ•°æ•ˆç‡ (åŸºäºèµ·å§‹ç‚¹åˆ°ç†è®ºç›®æ ‡ç‚¹çš„è·ç¦»)
        # Distance (Start -> Ground Truth)
        gt_pos = data["ground_truth_pose"][:3]
        start_pos = data["start_pose"][:3]
        dist_xy = np.linalg.norm(gt_pos[:2] - start_pos[:2])
        dist_z = abs(gt_pos[2] - start_pos[2])
        ideal_path_len = dist_xy + dist_z # mm
        
        # å®šä¹‰â€œæ ‡å‡†æ­¥é•¿â€ åœ¨è®­ç»ƒæ•°æ®é›†ä¸­ï¼Œæ¯ä¸€æ­¥(0.1s)å¹³å‡ç§»åŠ¨å¤šå°‘æ¯«ç±³
        REF_STEP_LEN_MM = 5.0 
        
                
        # å‡è®¾ç†è®ºé€Ÿåº¦ 100mm/s, 10Hz -> 10mm/step
        # é¿å…é™¤ä»¥0
        opt_steps = max(1, int(ideal_path_len / REF_STEP_LEN_MM))
        step_ratio = data["steps"] / opt_steps

        # 4. æœ€ç»ˆè¯¯å·® (æ ¸å¿ƒæŒ‡æ ‡)
        final_pos = data["final_pos_mm"]
        
        # A. ä½ç½®è¯¯å·® (mm)
        pos_error = np.linalg.norm(final_pos - gt_pos)
        
        # B. è§’åº¦è¯¯å·® (degree)
        # Ground Truth çš„ RPY (å‡è®¾ JSON åä¸‰ä½æ˜¯ rad)
        gt_rpy = data["ground_truth_pose"][3:] 
        final_rpy = data["final_rpy_rad"]
        
        # ç®€å•è®¡ç®— RPY çš„æ¬§æ°è·ç¦»ä½œä¸ºè¯¯å·®å‚è€ƒ (æ›´ä¸¥è°¨å¯ä»¥ç”¨å››å…ƒæ•°)
        # å°†å¼§åº¦è½¬ä¸ºè§’åº¦è®¡ç®—å·®å€¼
        diff_rpy_deg = np.degrees(np.abs(final_rpy - gt_rpy))
        # å¤„ç†å‘¨æœŸæ€§ (ä¾‹å¦‚ 359åº¦ å’Œ 1åº¦ å·®2åº¦) - ç®€å•åœºæ™¯å¯å¿½ç•¥ï¼Œè¿™é‡Œåšä¸ªç®€åŒ–æ±‚å’Œ
        rot_error = np.sum(diff_rpy_deg) # ç´¯è®¡è§’åº¦è¯¯å·®

        return {
            "success": 1.0 if data["success"] else 0.0,
            "time": duration,
            "jerk": avg_jerk,
            "step_ratio": step_ratio,
            "pos_error": pos_error,
            "rot_error": rot_error,
            "opt_steps": opt_steps  
        }

    def print_summary(self):
        if not self.episode_metrics:
            print("No metrics data.")
            return

        N = len(self.episode_metrics)
        total_episodes = len(self.episode_metrics)
        success_list = [m for m in self.episode_metrics if m["success"] == 1.0]
        num_success = len(success_list)
        avg_success = (num_success / total_episodes) * 100.0
        # 3. è®¡ç®—å…¶ä»–æŒ‡æ ‡ (ä»…åŸºäºæˆåŠŸæ¡ˆä¾‹)
        if num_success > 0:
            avg_time = np.mean([m["time"] for m in success_list])
            avg_jerk = np.mean([m["jerk"] for m in success_list])
            avg_step_ratio = np.mean([m["step_ratio"] for m in success_list])
            avg_pos_error = np.mean([m["pos_error"] for m in success_list])
            avg_rot_error = np.mean([m["rot_error"] for m in success_list])
            
            # ä¹Ÿå¯ä»¥ç®—ä¸€ä¸‹æ ‡å‡†å·®(std)çœ‹ç¨³å®šæ€§ï¼Œè¿™é‡Œå…ˆåªå±•ç¤ºå‡å€¼
        else:
            # å¦‚æœä¸€æ¬¡éƒ½æ²¡æˆåŠŸï¼Œå…¶ä»–æŒ‡æ ‡æ²¡æœ‰æ„ä¹‰
            avg_time = 0.0
            avg_jerk = 0.0
            avg_step_ratio = 0.0
            avg_pos_error = 0.0
            avg_rot_error = 0.0
            
        # avg_success = np.mean([m["success"] for m in self.episode_metrics]) * 100.0
        # avg_time = np.mean([m["time"] for m in self.episode_metrics])
        # avg_jerk = np.mean([m["jerk"] for m in self.episode_metrics])
        # avg_step_ratio = np.mean([m["step_ratio"] for m in self.episode_metrics])
        # avg_pos_error = np.mean([m["pos_error"] for m in self.episode_metrics])
        # avg_rot_error = np.mean([m["rot_error"] for m in self.episode_metrics])

        if num_success > 0:
            print("\n" + "="*60)
            print(f"ğŸ“Š é‡åŒ–æµ‹è¯•æŠ¥å‘Š (å·²æµ‹: {N} è½®)")
            print("="*60)
            print(f"âœ… æˆåŠŸç‡ (Success Rate):     {avg_success:.1f}%")
            print(f"ğŸ¯ å¹³å‡ä½ç½®è¯¯å·® (Pos Error): {avg_pos_error:.2f} mm")
            print(f"ğŸ“ å¹³å‡è§’åº¦è¯¯å·® (Rot Error): {avg_rot_error:.2f} deg")
            print(f"â±ï¸ å¹³å‡è€—æ—¶ (Time):          {avg_time:.2f} s")
            print(f"ğŸ‘£ æ­¥æ•°æ¯” (Actual/Optimal):   {avg_step_ratio:.2f}")
            print(f"ğŸ“‰ è½¨è¿¹å¹³æ»‘åº¦ (Jerk):        {avg_jerk:.4f}")
            print("="*60 + "\n")
        else:
            print("-" * 40)
            print("  [æ— æˆåŠŸæ¡ˆä¾‹ï¼Œæ— æ³•è®¡ç®—æ€§èƒ½æŒ‡æ ‡]")
            
    def print_current_metrics(self, metrics):
        """æ‰“å°å½“å‰è¿™ä¸€è½®çš„è¯¦ç»†æŒ‡æ ‡"""
        status_str = "âœ… Success" if metrics["success"] == 1.0 else "âŒ Failure"
        
        print("-" * 40)
        print(f"ğŸ“ æœ¬è½®è¯¦ç»†æ•°æ® ({status_str})")
        print(f"   â±ï¸ è€—æ—¶:       {metrics['time']:.2f} s")
        print(f"   ğŸ¯ ä½ç½®è¯¯å·®:   {metrics['pos_error']:.2f} mm")
        print(f"   ğŸ“ è§’åº¦è¯¯å·®:   {metrics['rot_error']:.2f} deg")
        print(f"   ğŸ‘£ æ­¥æ•°æ¯”:     {metrics['step_ratio']:.2f} (Opt: {metrics['opt_steps']:.0f})")
        print(f"   ğŸ“‰ å¹³æ»‘åº¦:     {metrics['jerk']:.4f}")
        print("-" * 40)
# -----------------------------------------------------------------------------
# ã€ä¿®å¤ç‰ˆã€‘Docker ä¸“ç”¨æ— å¤´å¯è§†åŒ–å™¨
# -----------------------------------------------------------------------------
class DebugVisualizer:
    def __init__(self, safe_z_limit, save_dir):
        # å¢åŠ ç”»å¸ƒé«˜åº¦ï¼Œæ”¹ä¸º 3è¡Œ 2åˆ—
        self.fig, self.axs = plt.subplots(3, 2, figsize=(10, 12))
        self.safe_z_limit = safe_z_limit
        self.save_path = os.path.join(save_dir, "live_debug_status.png")
        
        # --- å¸ƒå±€å®šä¹‰ ---
        # Row 1: ç›¸æœº
        self.ax_cam1 = self.axs[0, 0]
        self.ax_cam2 = self.axs[0, 1]
        
        # Row 2: ç©ºé—´è½¨è¿¹ (å·¦: XYå¹³é¢, å³: Zé«˜åº¦)
        self.ax_xy_plane = self.axs[1, 0]
        self.ax_z = self.axs[1, 1]
        
        # Row 3: æ•°å€¼æ›²çº¿ (å·¦: XYéšæ—¶é—´å˜åŒ–, å³: å¤¹çˆª)
        self.ax_xy_time = self.axs[2, 0]
        self.ax_grip = self.axs[2, 1]
        
        # --- åˆå§‹åŒ–æ ·å¼ ---
        # 1. XY å¹³é¢ (ä¿¯è§†å›¾)
        self.ax_xy_plane.set_title("XY Trajectory (Top-Down View)")
        self.ax_xy_plane.set_xlabel("X (mm)")
        self.ax_xy_plane.set_ylabel("Y (mm)")
        self.ax_xy_plane.grid(True)
        # self.ax_xy_plane.set_aspect('equal', 'datalim') # ä¿æŒæ¯”ä¾‹ï¼Œé˜²æ­¢åœ†å½¢å˜æ¤­åœ†
        self.ax_xy_plane.set_aspect('equal', adjustable='box')
        
        # 2. Z è½´
        self.ax_z.set_title("Z Trajectory (Height)")
        self.ax_z.set_ylabel("Z (mm)")
        self.ax_z.axhline(y=safe_z_limit, color='r', linestyle='--', label='Limit')
        self.ax_z.grid(True)
        
        # 3. XY æ—¶é—´åºåˆ—
        self.ax_xy_time.set_title("X & Y over Time (Steps)")
        self.ax_xy_time.set_ylabel("Position (mm)")
        self.ax_xy_time.grid(True)
        
        # 4. å¤¹çˆª
        self.ax_grip.set_title("Gripper Intent")
        self.ax_grip.set_ylim(-0.1, 1.1)
        self.ax_grip.axhline(y=0.8, color='g', linestyle='--', label='Trigger')
        self.ax_grip.grid(True)

        print(f"[Vis] Debug visualization will be saved to: {self.save_path}")

    def _clear_lines(self, ax):
        """è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨æ¸…é™¤å›¾è¡¨ä¸­çš„çº¿æ¡"""
        for line in list(ax.lines):
            line.remove()
        # æ¸…é™¤å›¾ä¾‹
        if ax.get_legend() is not None:
            ax.get_legend().remove()

    def update(self, obs, action_chunk, robot_arm):
        # --- 1. ç»˜åˆ¶å›¾åƒ ---
        self.ax_cam1.clear(); self.ax_cam1.set_title("Left Wrist")
        self.ax_cam1.imshow(obs['cam_left_wrist'])
        self.ax_cam1.axis('off')
        
        self.ax_cam2.clear(); self.ax_cam2.set_title("Right Wrist")
        self.ax_cam2.imshow(obs['cam_right_wrist'])
        self.ax_cam2.axis('off')
        
        # 1. è·å–å½“å‰æœºæ¢°è‡‚çš„ç»å¯¹ç¬›å¡å°”åæ ‡ (ä½œä¸ºèµ·ç‚¹)
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è°ƒç”¨ robot_arm çš„ get_positionï¼Œæ³¨æ„å•ä½è½¬æ¢
        code, curr_pose = robot_arm.get_position(is_radian=True)
        if code != 0: return # è¯»ä¸åˆ°å°±ç®—äº†
        curr_x, curr_y, curr_z = curr_pose[0], curr_pose[1], curr_pose[2]
        # --- 2. è®¡ç®—è½¨è¿¹æ•°æ® (FK) ---
        pred_x, pred_y, pred_z = [], [], []
        # è®°å½•èµ·å§‹ç‚¹çš„ç»å¯¹åæ ‡
        start_x, start_y, start_z = curr_x, curr_y, curr_z
        # ç´¯è®¡æ¨æ¼”
        sim_x, sim_y, sim_z = curr_x, curr_y, curr_z
        for i in range(len(action_chunk)):
            # action_chunk[i] æ˜¯ [dx, dy, dz, ...] (å•ä½: ç±³)
            dx = action_chunk[i][0] * 1000.0 # è½¬æ¯«ç±³
            dy = action_chunk[i][1] * 1000.0
            dz = action_chunk[i][2] * 1000.0
            
            cur_pred_x = start_x + dx
            cur_pred_y = start_y + dy
            cur_pred_z = start_z + dz
            
            pred_x.append(cur_pred_x)
            pred_y.append(cur_pred_y)
            pred_z.append(cur_pred_z)
        
       
        steps = np.arange(len(pred_x)) # æ—¶é—´æ­¥

        # --- 3. ç»˜åˆ¶ XY å¹³é¢è½¨è¿¹ (ä¿¯è§†å›¾) ---
        self._clear_lines(self.ax_xy_plane)
        self.ax_xy_plane.plot(pred_x, pred_y, 'b-o', alpha=0.6, markersize=4, label='Path')
        if pred_x:
            self.ax_xy_plane.plot(pred_x[0], pred_y[0], 'go', markersize=8, label='Start')
            self.ax_xy_plane.plot(pred_x[-1], pred_y[-1], 'rx', markersize=8, label='End')
            
            # åŠ¨æ€è°ƒæ•´è§†é‡
            mid_x, span_x = (np.min(pred_x) + np.max(pred_x))/2, (np.max(pred_x) - np.min(pred_x))
            mid_y, span_y = (np.min(pred_y) + np.max(pred_y))/2, (np.max(pred_y) - np.min(pred_y))
            max_span = max(span_x, span_y, 20) 
            self.ax_xy_plane.set_xlim(mid_x - max_span, mid_x + max_span)
            self.ax_xy_plane.set_ylim(mid_y - max_span, mid_y + max_span)
            
        self.ax_xy_plane.legend(loc='upper right', fontsize='small')

        # --- 4. ç»˜åˆ¶ Z è½´é«˜åº¦ ---
        self._clear_lines(self.ax_z)
        self.ax_z.axhline(y=self.safe_z_limit, color='r', linestyle='--') # é™ä½çº¿
        self.ax_z.plot(steps, pred_z, 'b-o', markersize=4)
        # åŠ¨æ€è°ƒæ•´ Z è½´èŒƒå›´ï¼Œæ–¹ä¾¿çœ‹æ¸…æ˜¯å¦è´´åœ°
        if pred_z:
            min_z = min(min(pred_z), self.safe_z_limit)
            self.ax_z.set_ylim(min_z - 20, max(pred_z) + 20)

        # --- 5. ç»˜åˆ¶ XY æ—¶é—´åºåˆ— ---
        self._clear_lines(self.ax_xy_time)
        self.ax_xy_time.plot(steps, pred_x, 'c--', label='X')
        self.ax_xy_time.plot(steps, pred_y, 'm--', label='Y')
        self.ax_xy_time.legend(loc='best', fontsize='small')

        # --- 6. ç»˜åˆ¶å¤¹çˆª (ä¿æŒä¸å˜) ---
        grip_vals = action_chunk[:, 6]
        self._clear_lines(self.ax_grip)
        self.ax_grip.axhline(y=0.8, color='g', linestyle='--')
        self.ax_grip.plot(steps, grip_vals, 'k-x')

        # --- 7. ä¿å­˜å›¾ç‰‡ ---
        try:
            self.fig.canvas.draw()
            img_rgba = np.asarray(self.fig.canvas.buffer_rgba())
            image = cv2.cvtColor(img_rgba, cv2.COLOR_RGBA2BGR)
            cv2.imwrite(self.save_path, image)
        except Exception as e:
            print(f"[Vis Error] {e}")
# -----------------------------------------------------------------------------
# é”®ç›˜ç›‘å¬çº¿ç¨‹ (è½»é‡çº§)
# -----------------------------------------------------------------------------
class KeyboardThread(threading.Thread):
    def __init__(self):
        super().__init__()
        self.daemon = True
        self.last_key = None
        self.running = True

    def run(self):
        fd = sys.stdin.fileno()
        old_term = termios.tcgetattr(fd)
        new_term = termios.tcgetattr(fd)
        new_term[3] = (new_term[3] & ~termios.ICANON & ~termios.ECHO)
        termios.tcsetattr(fd, termios.TCSANOW, new_term)
        try:
            while self.running:
                dr, _, _ = select.select([sys.stdin], [], [], 0.1)
                if dr:
                    self.last_key = sys.stdin.read(1)
        finally:
            termios.tcsetattr(fd, termios.TCSANOW, old_term)

    def get_and_clear_key(self):
        k = self.last_key
        self.last_key = None
        return k

    def stop(self):
        self.running = False

# -----------------------------------------------------------------------------
# å·¥å…·ç±» (Sampler, Visualizer) - ä¿æŒä¸å˜
# -----------------------------------------------------------------------------
class TaskVisualizer:
    def __init__(self, save_dir, result_name, boundary_points, home_pos):
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.save_path = self.save_dir / result_name
        self.boundary = boundary_points
        self.home_pos = home_pos
        
        self.scale = 1.5 
        self.offset_x = -np.min(boundary_points[:, 0]) * self.scale + 50
        self.offset_y = -np.min(boundary_points[:, 1]) * self.scale + 50
        self.canvas = self._load_or_create()

    def _to_pixel(self, x, y):
        return int(x * self.scale + self.offset_x), int(y * self.scale + self.offset_y)

    def _load_or_create(self):
        if self.save_path.exists(): return cv2.imread(str(self.save_path))
        w = int((np.max(self.boundary[:, 0]) - np.min(self.boundary[:, 0])) * self.scale + 100)
        h = int((np.max(self.boundary[:, 1]) - np.min(self.boundary[:, 1])) * self.scale + 100)
        img = np.ones((h, w, 3), dtype=np.uint8) * 255
        pts = np.array([self._to_pixel(p[0], p[1]) for p in self.boundary], np.int32).reshape((-1, 1, 2))
        cv2.polylines(img, [pts], True, (0, 0, 0), 2)
        cv2.circle(img, self._to_pixel(*self.home_pos[:2]), 8, (255, 0, 0), -1)
        return img

    def update_result(self, pose, success):
        pt = self._to_pixel(pose[0], pose[1])
        color = (0, 255, 0) if success else (0, 0, 255)
        end = (int(pt[0] + 25 * np.cos(pose[5])), int(pt[1] + 25 * np.sin(pose[5])))
        cv2.circle(self.canvas, pt, 4, color, -1)
        cv2.arrowedLine(self.canvas, pt, end, color, 2, tipLength=0.3)
        save_path_str = str(self.save_path)
        if not self.save_dir.exists():
            self.save_dir.mkdir(parents=True, exist_ok=True)
        if not (save_path_str.endswith(".png") or save_path_str.endswith(".jpg")):
            print(f"[Warn] Filename '{save_path_str}' has no valid extension. Appending .png")
            self.save_path = self.save_path.with_suffix(".png")
            save_path_str = str(self.save_path)
        # æ‰“å°è°ƒè¯•ä¿¡æ¯ (çœ‹çœ‹ç©¶ç«Ÿå­˜åˆ°å“ªå»äº†)
        print(f"[Debug] Saving image to: {save_path_str}")
        
        try:
            cv2.imwrite(save_path_str, self.canvas)
            print(f"[Vis] Result saved successfully.")
        except Exception as e:
            print(f"[Error] Failed to save image: {e}")

class TaskSampler:
    def __init__(self, json_path, progress_file=None, resume=False):
        """
        :param json_path: åŸå§‹å®Œæ•´æµ‹è¯•ç‚¹æ–‡ä»¶ (test_points.json)
        :param progress_file: è¿›åº¦è®°å½•æ–‡ä»¶è·¯å¾„ (test_progress.json)
        :param resume: æ˜¯å¦å°è¯•ä»è¿›åº¦æ–‡ä»¶æ¢å¤
        """
        self.original_json_path = json_path
        self.progress_file = progress_file
        
        if not os.path.exists(json_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç‚¹ä½æ–‡ä»¶: {json_path}ã€‚è¯·å…ˆè¿è¡Œç”Ÿæˆè„šæœ¬ã€‚")
        
        with open(json_path, 'r') as f:
            data = json.load(f)
            # åŸå§‹å…¨é›†ï¼ˆé¡ºåºå¿…é¡»å›ºå®šï¼‰
            self.all_points_original = data["grid"] + data["boundary"]
        # 2. å¤„ç†æ–­ç‚¹æ¢å¤é€»è¾‘
        if resume and progress_file and os.path.exists(progress_file):
            print(f"[Sampler] å‘ç°è¿›åº¦æ–‡ä»¶: {progress_file}ï¼Œå°è¯•æ¢å¤...")
            try:
                with open(progress_file, 'r') as f:
                    progress_data = json.load(f)
                
                # è¯»å–å‰©ä½™ç‚¹åˆ—è¡¨
                self.remaining_points = progress_data.get("remaining_points", [])
                self.completed_count = progress_data.get("completed_count", 0)
                
                # æ ¡éªŒä¸€ä¸‹ (å¯é€‰)
                if not self.remaining_points and self.completed_count > 0:
                    print("[Sampler] âš ï¸ è¿›åº¦æ–‡ä»¶æ˜¾ç¤ºæ‰€æœ‰ç‚¹å·²æµ‹è¯•å®Œæ¯•ï¼")
                else:
                    print(f"[Sampler] âœ… æˆåŠŸæ¢å¤è¿›åº¦ã€‚å·²æµ‹: {self.completed_count}, å‰©ä½™: {len(self.remaining_points)}")
            except Exception as e:
                print(f"[Sampler] âŒ è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥ ({e})ï¼Œå°†é‡ç½®ä¸ºå…¨éƒ¨æµ‹è¯•ç‚¹ã€‚")
                self.remaining_points = list(self.all_points_original)
                self.completed_count = 0
        else:
            # ä¸ç»­æµ‹ï¼Œæˆ–è€…æ²¡æœ‰è¿›åº¦æ–‡ä»¶ -> é‡ç½®
            print("[Sampler] åˆå§‹åŒ–æ–°æµ‹è¯•åºåˆ—...")
            self.remaining_points = list(self.all_points_original)
            self.completed_count = 0
        
            # å¦‚æœå¼€å¯äº†ç»­æµ‹æ¨¡å¼ä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç«‹åˆ»åˆ›å»ºä¸€ä¸ªåˆå§‹çŠ¶æ€
            if resume and progress_file:
                self.save_progress()
        self.total_original_count = len(self.all_points_original)
        self.current_target = None
                
        # å°† Grid å’Œ Boundary çš„ç‚¹åˆå¹¶æˆä¸€ä¸ªåˆ—è¡¨ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ
        # å¦‚æœä½ æƒ³å…ˆæµ‹ Boundaryï¼Œå¯ä»¥æŠŠé¡ºåºåè¿‡æ¥
        # self.all_points = data["grid"] + data["boundary"]
        # self.total_count = len(self.all_points)
        self.current_idx = 0
        
        print(f"[Sampler] Loaded {self.total_original_count} points (Grid + Boundary).")
    
    def get_next_target(self):
        """è·å–ä¸‹ä¸€ä¸ªç‚¹ï¼Œå¹¶ä»å‰©ä½™åˆ—è¡¨ä¸­ç§»é™¤"""
        if not self.remaining_points:
            return None, self.completed_count, self.total_original_count
        # å–å‡ºç¬¬ä¸€ä¸ª
        self.current_target = self.remaining_points[0]
        self.current_target[2] = OBJECT_Z
        
        # è¿”å› (pose, å½“å‰æ˜¯ç¬¬å‡ ä¸ª, æ€»æ•°)
        # æ³¨æ„ï¼šè¿™é‡Œ idx è¿”å›çš„æ˜¯ "è¿™æ˜¯ç¬¬å‡ ä¸ªè¢«æµ‹çš„"ï¼Œæ–¹ä¾¿æ˜¾ç¤ºè¿›åº¦
        return self.current_target, self.completed_count + 1, self.total_original_count
        # if self.current_idx < self.total_count:
        #     pose = self.all_points[self.current_idx]
        #     self.current_idx += 1
        #     return pose, self.current_idx, self.total_count
        # return None, -1, self.total_count
    
    def mark_current_done(self):
        """ç¡®è®¤å½“å‰ç‚¹æµ‹è¯•å®Œæˆï¼Œä¿å­˜è¿›åº¦"""
        if self.remaining_points:
            # ç§»é™¤å·²å®Œæˆçš„ç‚¹ (å°±æ˜¯åˆ—è¡¨ç¬¬ä¸€ä¸ª)
            self.remaining_points.pop(0)
            self.completed_count += 1
            self.save_progress()
    def save_progress(self):
        """å°†å½“å‰å‰©ä½™ç‚¹åˆ—è¡¨å†™å…¥ç£ç›˜"""
        if not self.progress_file: return
        
        data = {
            "completed_count": self.completed_count,
            "remaining_points": self.remaining_points
        }
        
        #ä¸ºäº†å®‰å…¨ï¼Œå…ˆå†™ä¸´æ—¶æ–‡ä»¶å†é‡å‘½å
        temp_file = self.progress_file + ".tmp"
        with open(temp_file, 'w') as f:
            json.dump(data, f, indent=4)
        os.replace(temp_file, self.progress_file)
        print(f"[Sampler] è¿›åº¦å·²ä¿å­˜ ({len(self.remaining_points)} left)")
         
    def _generate_boundary_path(self, vertices, step_size):
        path = []
        num_v = len(vertices)
        for i in range(num_v):
            p_curr = vertices[i]
            p_next = vertices[(i + 1) % num_v]
            vec = p_next - p_curr
            dist = np.linalg.norm(vec)
            steps = int(max(1, dist / step_size))
            unit_vec = vec / dist
            for s in range(steps):
                path.append(p_curr + unit_vec * (s * step_size))
        return np.array(path)
    def _refill(self):
        self.grid_indices = [(r, c) for r in range(self.grid_rows) for c in range(self.grid_cols)]
        random.shuffle(self.grid_indices)
    def is_inside(self, x, y):
        return all(np.dot(eq, [x, y, 1]) <= 1e-6 for eq in self.hull.equations)
    def get_target(self, mode='grid'):
        rand_yaw = BASE_YAW + random.uniform(YAW_RANDOM_RANGE[0], YAW_RANDOM_RANGE[1])
        if mode == 'boundary': # Simplified for brevity
            #  return [np.mean(BOUNDARY_POINTS_2D[:,0]), np.mean(BOUNDARY_POINTS_2D[:,1]), FIXED_Z, FIXED_ROLL, FIXED_PITCH, BASE_YAW]
            if len(self.path_points_2d) > 0:
                idx = random.randint(0, len(self.path_points_2d) - 1)
                pt = self.path_points_2d[idx]
                return [pt[0], pt[1], FIXED_Z, FIXED_ROLL, FIXED_PITCH, rand_yaw]
            else:
                # ä¿åº•é€»è¾‘
                c = np.mean(BOUNDARY_POINTS_2D, axis=0)
                return [c[0], c[1], FIXED_Z, FIXED_ROLL, FIXED_PITCH, rand_yaw]
        else: # Grid mode
            # å°è¯•å¤šæ¬¡é‡‡æ ·ç›´åˆ°åœ¨å‡¸åŒ…å†…
            for _ in range(32):
                if not self.grid_indices: self._refill()
                r, c = self.grid_indices.pop()
                
                step_x = (self.max_x - self.min_x) / self.grid_cols
                step_y = (self.max_y - self.min_y) / self.grid_rows
                
                cell_min_x = self.min_x + c * step_x
                cell_max_x = self.min_x + (c + 1) * step_x
                cell_min_y = self.min_y + r * step_y
                cell_max_y = self.min_y + (r + 1) * step_y

                for _ in range(10): # åœ¨æ ¼å­å†…å°è¯•å‡ æ¬¡
                    tx = random.uniform(cell_min_x, cell_max_x)
                    ty = random.uniform(cell_min_y, cell_max_y)
                    if self.is_inside(tx, ty):
                        # æ³¨æ„è¿™é‡Œä½¿ç”¨çš„æ˜¯ rand_yaw
                        return [tx, ty, FIXED_Z, FIXED_ROLL, FIXED_PITCH, rand_yaw]
            
            # å¦‚æœå®åœ¨æ‰¾ä¸åˆ°ï¼Œè¿”å›ä¸­å¿ƒç‚¹ (ä¿åº•)
            c = np.mean(BOUNDARY_POINTS_2D, axis=0)
            return [c[0], c[1], FIXED_Z, FIXED_ROLL, FIXED_PITCH, rand_yaw]
# -----------------------------------------------------------------------------
# ç¡¬ä»¶å°è£… (æ ¸å¿ƒä¿®æ­£ï¼šFlush Camera + Restore execute_action)
# -----------------------------------------------------------------------------
class XArmHardware:
    def __init__(self, ip, camera_indices):
        print(f"Connecting to xArm at {ip}...")
        self.arm = XArmAPI(ip)
        self.arm.motion_enable(enable=True)
        self.arm.set_mode(0); self.arm.set_state(0)
        self.arm.set_tgpio_modbus_baudrate(baud=115200)
        
        self.caps = {}
        for name, idx in camera_indices.items():
            cap = cv2.VideoCapture(idx)
            cap.set(3, 640); cap.set(4, 480); cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            self.caps[name] = cap
        
        self.current_gripper_state = 0.0
        # self.open_gripper()
        time.sleep(1.5)

    def get_current_cartesian(self):
        # è¾…åŠ©å‡½æ•°ï¼šè·å–å½“å‰ç»å¯¹åæ ‡ (XYZ+RPY)ï¼Œå•ä½è½¬ä¸ºç±³
        code, pose = self.arm.get_position(is_radian=True)
        if code != 0: return None
        pose = np.array(pose, dtype=np.float32)
        pose[:3] /= 1000.0 # è¿™é‡Œçš„å•ä½å¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼å¦‚æœè®­ç»ƒé™¤ä»¥1000ï¼Œè¿™é‡Œä¹Ÿè¦é™¤
        return pose
    
    def close_gripper(self):
        self.arm.getset_tgpio_modbus_data([0x01, 0x10, 0x01, 0x02, 0x00, 0x02, 0x04, 0x0, 0x0, 0x2E, 0xE0])
        self.arm.getset_tgpio_modbus_data([0x01, 0x06, 0x01, 0x08, 0x00, 0x01])
        self.current_gripper_state = 1.0

    def open_gripper(self):
        self.arm.getset_tgpio_modbus_data([0x01, 0x10, 0x01, 0x02, 0x00, 0x02, 0x04, 0x0, 0x0, 0x00, 0x00])
        self.arm.getset_tgpio_modbus_data([0x01, 0x06, 0x01, 0x08, 0x00, 0x01])
        self.current_gripper_state = 0.0

    # ã€æ–°å¢ã€‘æ¸…ç©ºç›¸æœºç¼“å†²åŒºï¼Œè§£å†³å»¶è¿Ÿé—®é¢˜çš„æ ¸å¿ƒ
    def flush_cameras(self):
        for cap in self.caps.values():
            for _ in range(4): # è¿ç»­è¯»å–å‡ æ¬¡ï¼Œä¸¢å¼ƒæ—§å¸§
                cap.grab()

    def get_observation(self) -> dict:
        obs = {}
        for name, cap in self.caps.items():
            ret, frame = cap.read()
            if not ret: frame = np.zeros((480, 640, 3), dtype=np.uint8)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            if name in CROP_CONFIGS:
                x, y, w, h = CROP_CONFIGS[name]
                frame = frame[y:y+h, x:x+w]
            obs[name] = image_tools.convert_to_uint8(frame)
        obs["cam_high"] = np.zeros((224, 224, 3), dtype=np.uint8)
        
        code, joints_rad = self.arm.get_servo_angle(is_radian=True)
        if code != 0: joints_rad = [0.0] * 7
        obs["state"] = np.append(joints_rad[:6], self.current_gripper_state)
        return obs

    def recover_from_error(self, target_mode=0):
        """
        target_mode: æ¢å¤åå¸Œæœ›è¿›å…¥çš„æ¨¡å¼ã€‚
        0: ä½ç½®æ¨¡å¼ (ç”¨äº move_to)
        1: ä¼ºæœæ¨¡å¼ (ç”¨äº set_servo_angle_j / å®æ—¶æ¨ç†æ‰§è¡Œ)
        """
        print(f"\n[Recovery] !!! å¯åŠ¨è‡ªåŠ¨æ¢å¤ç¨‹åºï¼Œç›®æ ‡æ¨¡å¼: {target_mode}")
        
        if self.arm is None: return

        # 1. åœæ­¢å¹¶æ¸…é™¤é”™è¯¯ (è¿™ä¸€æ­¥ä¸åˆ†æ¨¡å¼)
        self.arm.set_state(4)
        time.sleep(0.2)
        self.arm.clean_error()
        self.arm.clean_warn()
        time.sleep(0.2)

        # 2. é‡æ–°ä½¿èƒ½
        self.arm.motion_enable(enable=True)
        time.sleep(0.5)

        # 3. å…³é”®ï¼šæ­£ç¡®åˆ‡æ¢æ¨¡å¼
        # å…ˆ set_modeï¼Œå† set_state
        self.arm.set_mode(target_mode)
        time.sleep(0.2)
        self.arm.set_state(0)
        
        # å¢åŠ ä¸€ä¸ªæ£€æŸ¥å¾ªç¯ï¼Œç¡®ä¿æ¨¡å¼åˆ‡æ¢æˆåŠŸåå†é€€å‡ºå‡½æ•°
        # è¿™æ ·å¯ä»¥é¿å…é€€å‡ºå‡½æ•°åç«‹åˆ»æ‰§è¡Œ API å¯¼è‡´çš„ mode incorrect è­¦å‘Š
        for i in range(10):
            # æ£€æŸ¥ SDK ç¼“å­˜çš„æ¨¡å¼æ˜¯å¦å·²æ›´æ–°
            if self.arm.mode == target_mode:
                break
            time.sleep(0.1)
        
        if target_mode == 1:
            # å¦‚æœè¦å›åˆ°ä¼ºæœæ¨¡å¼ï¼Œå…ˆç¡®ä¿å®ƒåœ¨æ¨¡å¼ 0 ä¸‹ç¨å¾®å¾€ä¸ŠæŠ¬ä¸€ç‚¹ï¼Œè„±ç¦»ç¢°æ’ç‚¹
            self.arm.set_mode(0)
            self.arm.set_state(0)
            curr_pos = self.arm.get_position()[1]
            curr_pos[2] += 20.0 # å‘ä¸ŠæŠ¬ 20mm
            self.arm.set_position(*curr_pos, wait=True)
            
            # æŠ¬å‡å®Œåå†åˆ‡æ¢åˆ°æ¨ç†æ‰€éœ€çš„æ¨¡å¼ 1
            self.arm.set_mode(1)
            self.arm.set_state(0)

        print(f"[Recovery] æ¢å¤å®Œæˆï¼Œå½“å‰æ¨¡å¼: {self.arm.mode}")
        
    def execute_action(self, action_delta):
        """
        æ‰§è¡Œå•æ­¥åŠ¨ä½œ (Cartesian Delta Mode)
        action_delta: [dx, dy, dz, dRx, dRy, dRz, gripper] (å•ä½: ç±³, å¼§åº¦)
        """
        # print(f"[Debug] Action Delta: {action_delta[:3]}")
        # 1. è·å–å½“å‰ç»å¯¹ä½å§¿ (ç±³)
        curr_pose = self.get_current_cartesian()
        
        # 2. è®¡ç®—ç›®æ ‡ç»å¯¹ä½å§¿ (Current + Delta)
        # æ³¨æ„ï¼šè¿™é‡Œåšç®€å•çš„æ¬§æ‹‰è§’å åŠ ã€‚å¯¹äºå°æ­¥é•¿æ§åˆ¶é€šå¸¸è¶³å¤Ÿã€‚
        target_pose = curr_pose.copy()
        target_pose[:6] += action_delta[:6] 
        
        # 3. Zè½´å®‰å…¨é™ä½ (ç±³ -> ç±³)
        # æ³¨æ„ MIN_SAFE_Z æ˜¯æ¯«ç±³ï¼Œè¿™é‡Œè¦è½¬æˆç±³æ¯”è¾ƒï¼Œæˆ–è€…æŠŠ target è½¬å›æ¯«ç±³
        target_z_mm = target_pose[2] * 1000.0
        if target_z_mm < MIN_SAFE_Z:
            # print(f"[Safety] Limit Z: {target_z_mm:.1f} -> {MIN_SAFE_Z}")
            target_pose[2] = MIN_SAFE_Z / 1000.0

        # 4. å‡†å¤‡ IK è¾“å…¥ (ç±³ -> æ¯«ç±³)
        ik_target_pose = target_pose.copy()
        ik_target_pose[:3] *= 1000.0 # è½¬å› mm
        
        # 5. IK è§£ç®—
        # ret, target_joints = self.arm.get_inverse_kinematics(ik_target_pose, input_is_radian=True, return_is_radian=True)
        # æ”¹è¿›ä¸€ä¸‹
        ret, target_joints, actual_target_pose = self.find_reachable_ik(curr_pose, target_pose)
        if ret == 0:
            # 6. æ’å€¼æ‰§è¡Œ (ä¿æŒä½ åŸæœ‰çš„å¹³æ»‘é€»è¾‘)
            _, curr_joints_raw = self.arm.get_servo_angle(is_radian=True)
            
            
    
    
            curr_j = np.array(curr_joints_raw[:6])
            targ_j = np.array(target_joints[:6])
            
            diff = np.max(np.abs(np.array(curr_j[:6]) - np.array(target_joints[:6])))
            # print(f"[Debug] Max Joint Jump: {diff:.4f} rad")
            if diff > 6.28: # å¦‚æœä¸€æ­¥è·³å˜è¶…è¿‡ 0.5 å¼§åº¦ (çº¦30åº¦)
                print("!!! DANGER: Joint jump too large! Stop!")
                return False # æ‹’ç»æ‰§è¡Œ
            
            duration = (1.0 / CONTROL_FREQ) * SLOW_DOWN_FACTOR
            steps = int(duration * INTERPOLATION_FREQ)
            if steps < 1: steps = 1
            
            for i in range(1, steps + 1):
                alpha = i / steps
                interp = curr_j + (targ_j - curr_j) * alpha
                # ã€ä¿®æ”¹ã€‘å¢åŠ è¿”å›å€¼æ£€æŸ¥å’Œè‡ªåŠ¨æ¢å¤
                ret = self.arm.set_servo_angle_j(angles=np.append(interp, 0.0), is_radian=True)
                # å¦‚æœå‘é€æŒ‡ä»¤å¤±è´¥ (æ¯”å¦‚ code=9)
                if ret != 0:
                    print(f"[Hardware Error] set_servo_angle_j failed, code={ret}. Trying to recover...")
                    self.recover_from_error(target_mode=1) # æ¢å¤åç›´æ¥åˆ‡å›æ¨¡å¼ 1
                    return False # è¿™ä¸€æ­¥åŠ¨ä½œè·³è¿‡
                
                time.sleep(1.0 / INTERPOLATION_FREQ)
        else:
            print("[Error] IK Failed. Target unreachable.")
            return False

        # 7. å¤¹çˆª
        target_gripper = action_delta[6]
        if target_gripper > 0.8: self.close_gripper()
        elif target_gripper < 0.2: self.open_gripper()
        
        return True
        
    def find_reachable_ik(self, start_pose, end_pose, search_steps=5):
        """
        å¦‚æœåœ¨ end_pose IK å¤±è´¥ï¼Œåˆ™åœ¨ start å’Œ end ä¹‹é—´äºŒåˆ†æŸ¥æ‰¾æœ€è¿‘çš„å¯è¾¾ç‚¹ã€‚
        """
        # è½¬æ¢ä¸º mm ä»¥ä¾¿ SDK è®¡ç®—
        def get_ik(p):
            ik_p = p.copy()
            ik_p[:3] *= 1000.0
            return self.arm.get_inverse_kinematics(ik_p, input_is_radian=True, return_is_radian=True)

        # 1. é¦–å…ˆå°è¯•åŸå§‹ç›®æ ‡
        ret, joints = get_ik(end_pose)
        if ret == 0:
            return ret, joints, end_pose

        # 2. å¦‚æœå¤±è´¥ï¼Œå°è¯•å¯»æ‰¾â€œæŠ˜ä¸­ç‚¹â€
        # åœ¨å½“å‰ä½å§¿å’Œç›®æ ‡ä½å§¿ä¹‹é—´è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œä» 0.8, 0.6, 0.4... æ¯”ä¾‹å°è¯•
        print(f"[Warning] Original IK Failed. Searching for nearest reachable point...")
        
        # å°è¯•æ¯”ä¾‹ï¼š0.75, 0.5, 0.25
        for ratio in [0.75, 0.5, 0.25, 0.1]:
            temp_pose = start_pose + (end_pose - start_pose) * ratio
            ret, joints = get_ik(temp_pose)
            if ret == 0:
                print(f"[Recovery] Found reachable point at {ratio*100:.0f}% of original step.")
                return ret, joints, temp_pose

        return -1, None, None
            
        
    # # ã€è¿˜åŸã€‘å®Œå…¨æ¢å¤ Code A çš„æ‰§è¡Œé€»è¾‘ï¼Œå»æ‰æ‰€æœ‰é¢å¤–æ£€æµ‹
    # def execute_action(self, action_rad):
    #     # 1. å®‰å…¨é™ä½
    #     target_joints = [np.clip(a, l, h) for a, (l, h) in zip(action_rad[:6], JOINT_LIMITS)]
        
    #     # 2. Zè½´æ£€æŸ¥ä¸ä¿®æ­£
    #     ret, pose = self.arm.get_forward_kinematics(angles=target_joints, input_is_radian=True, return_is_radian=True)
    #     if ret == 0:
    #         model_z = pose[2]
            
    #         # åªæœ‰å½“æ¨¡å‹æƒ³å»çš„é«˜åº¦ ä½äº å®‰å…¨é™åˆ¶æ—¶ï¼Œæ‰è§¦å‘ä¿®æ­£
    #         if model_z < MIN_SAFE_Z:
    #             print(f"[DEBUG] Z Limit Triggered! Model wants: {model_z:.2f}, Limit: {MIN_SAFE_Z}")
                
    #             # æ„é€ ä¿®æ­£åçš„ä½å§¿ï¼ˆä¿æŒXYå’Œæ—‹è½¬ä¸å˜ï¼ŒåªæŠŠZæŠ¬é«˜åˆ°å®‰å…¨çº¿ï¼‰
    #             safe_pose = list(pose)
    #             safe_pose[2] = MIN_SAFE_Z
                
    #             # é‡æ–°è§£ç®—å…³èŠ‚è§’
    #             ret_ik, ik_joints = self.arm.get_inverse_kinematics(safe_pose, input_is_radian=True, return_is_radian=True)
    #             if ret_ik == 0: 
    #                 target_joints = list(ik_joints) # ä½¿ç”¨ä¿®æ­£åçš„å…³èŠ‚è§’
    #             else: 
    #                 print("[Error] IK Failed during Z-safety adjustment")
    #                 return # IK å¤±è´¥è·³è¿‡è¯¥æ­¥éª¤

    #     # 3. æ’å€¼è¿åŠ¨ (Time Dilation)
    #     code, current_joints = self.arm.get_servo_angle(is_radian=True)
    #     if code != 0: return

    #     curr_j = np.array(current_joints[:6])
    #     targ_j = np.array(target_joints[:6])
        
    #     duration = (1.0 / CONTROL_FREQ) * SLOW_DOWN_FACTOR
    #     steps = int(duration * INTERPOLATION_FREQ)
    #     if steps < 1: steps = 1
        
    #     # === æ ¸å¿ƒå¾ªç¯ï¼šè¿™é‡Œç»å¯¹ä¸èƒ½æœ‰ä»»ä½• IO é˜»å¡ ===
    #     for i in range(1, steps + 1):
    #         alpha = i / steps
    #         interp = curr_j + (targ_j - curr_j) * alpha
    #         self.arm.set_servo_angle_j(angles=np.append(interp, 0.0), is_radian=True)
    #         time.sleep(1.0 / INTERPOLATION_FREQ)
    #     # ==========================================

    #     # 4. å¤¹çˆª
    #     g = action_rad[6]
    #     if g > 0.8: self.close_gripper()
    #     elif g < 0.2: self.open_gripper()

    def move_home_scripted(self):
        self.arm.set_mode(0); self.arm.set_state(0)
        self.arm.set_position(*HOME_POS, speed=100, wait=True, is_radian=True)

    def move_to_start(self, target_action_rad):
        joints = [np.clip(a, l, h) for a, (l, h) in zip(target_action_rad[:6], JOINT_LIMITS)]
        self.arm.set_mode(0); self.arm.set_state(0)
        self.arm.set_servo_angle(angle=joints, speed=0.35, is_radian=True, wait=True)
        self.arm.set_mode(1); self.arm.set_state(0)
        time.sleep(0.5)

    def run_setup(self, target_pose):
        pose_A_up = list(POS_A); pose_A_up[2] += 100
        target_up = list(target_pose); target_up[2] += 100
        self.arm.set_mode(0); self.arm.set_state(0)
        try:
            self.arm.set_position(*pose_A_up, speed=300, wait=True, is_radian=True)
            self.arm.set_position(*POS_A, speed=300, wait=True, is_radian=True)
            self.open_gripper(); time.sleep(2.0)
            self.close_gripper(); time.sleep(2.0)
            self.arm.set_position(*pose_A_up, speed=300, wait=True, is_radian=True)
            self.move_home_scripted()
            self.arm.set_position(*target_up, speed=300, wait=True, is_radian=True)
            self.arm.set_position(*target_pose, speed=300, wait=True, is_radian=True)
            self.open_gripper(); time.sleep(1.5)
            self.arm.set_position(*target_up, speed=300, wait=True, is_radian=True)
            self.move_home_scripted()
        except Exception: self.move_home_scripted()

    def close(self):
        self.arm.disconnect()
        for cap in self.caps.values(): cap.release()
        
    def is_in_boundary(self, pose_mm, boundary_points):
        """
        æ£€æŸ¥ç¬›å¡å°”åæ ‡(mm)æ˜¯å¦åœ¨2Då‡¸åŒ…èŒƒå›´å†…
        pose_mm: [x, y, z, ...]
        """
        # æå– XY
        pt = (float(pose_mm[0]), float(pose_mm[1]))
        
        # è½¬æ¢ä¸º OpenCV éœ€è¦çš„ contour æ ¼å¼ (int)
        # æ³¨æ„ï¼šboundary_points_2d æ˜¯ floatï¼Œè¿™é‡Œä¸ºäº† pointPolygonTest æœ€å¥½ä¿æŒç²¾åº¦
        # pointPolygonTest æ”¯æŒ float è¾“å…¥ï¼Œä½† contour æœ€å¥½æ˜¯ float32
        contour = boundary_points.astype(np.float32)
        
        # measureDist=False, è¿”å› +1(å†…), -1(å¤–), 0(è¾¹)
        result = cv2.pointPolygonTest(contour, pt, False)
        return result >= 0

# -----------------------------------------------------------------------------
# ä¸»ç¨‹åº
# -----------------------------------------------------------------------------
def main():
    print(f"Loading Model: {CONFIG_NAME}...")
    config = _config.get_config(CONFIG_NAME)
    policy = policy_config.create_trained_policy(config, CHECKPOINT_DIR)
    
    robot = XArmHardware(ROBOT_IP, CAMERAS)
    sampler = TaskSampler(POINTS_FILE, progress_file=PROGRESS_FILE, resume=RESUME_TESTING)
    viz = TaskVisualizer(VIS_SAVE_DIR, RESULT_IMG_NAME, BOUNDARY_POINTS_2D, HOME_POS)
    debugger = DebugVisualizer(MIN_SAFE_Z, VIS_SAVE_DIR)
    recorder = MetricsRecorder()

    # å¯åŠ¨åå°é”®ç›˜ç›‘å¬
    kb = KeyboardThread()
    kb.start()
    # æš‚åœæ ‡å¿—ä½åˆå§‹åŒ–
    pause_requested = False 
    
    # prompt = "pick up the industrial components B"
    current_target = None
    
    # ã€ç§»é™¤äº†ã€‘ start_pose_abs = robot.get_current_cartesian() 
    # åŸå› ï¼šæ”¾åœ¨è¿™é‡Œä¼šå¯¼è‡´ç¬¬äºŒè½®æŠ“å–æ—¶åŸºå‡†ç‚¹å¤±æ•ˆ

    try:
        episode = 0
        
        while True:
            episode += 1
            print(f"\n=== Episode {episode} ===")
            
            # 1. è·å–ä¸‹ä¸€ä¸ªç›®æ ‡ç‚¹
            target_pose, idx, total = sampler.get_next_target()
            # å¦‚æœæ²¡æœ‰ç‚¹äº†ï¼Œç»“æŸç¨‹åº
            if target_pose is None:
                print("\n" + "="*50)
                print("ALL TEST POINTS COMPLETED!")
                print(f"Result image saved at: {viz.save_path}")
                print("="*50)
                # å¯é€‰ï¼šæµ‹è¯•å®Œæˆååˆ é™¤è¿›åº¦æ–‡ä»¶ï¼Œæ–¹ä¾¿ä¸‹æ¬¡é‡æ¥
                # if os.path.exists(PROGRESS_FILE): os.remove(PROGRESS_FILE)
                break
            print(f"\n=== Test Point {idx}/{total} ===")
            print(f"Target: {target_pose}")
            
            # 2. æœºå™¨äººå»ç›®æ ‡ç‚¹æ”¾ç½®ç‰©ä½“ (Setup)
            robot.run_setup(target_pose)
            print(">>> Setup Done. Starting Inference...")            
            
            # 3. æ¨ç†å‡†å¤‡
            robot.flush_cameras() 
            
            # ã€æ–°å¢ä½ç½®ã€‘åœ¨è¿™é‡Œè·å–æœ¬å›åˆçš„èµ·å§‹åŸºå‡†ç‚¹
            start_pose_abs = robot.get_current_cartesian()
            
            # å¼€å§‹è®°å½•ï¼šä¼ å…¥ èµ·å§‹ç‚¹ å’Œ ç†è®ºç›®æ ‡ç‚¹
            recorder.start_episode(start_pose_abs, target_pose)
            
            robot.arm.set_mode(1)
            robot.arm.set_state(0)
            time.sleep(0.5) # ç­‰å¾…æ¨¡å¼åˆ‡æ¢ç”Ÿæ•ˆ
            #   åˆå§‹åŒ–æ ‡å¿—ä½
            just_recovered = False 
            
            # ã€åˆ é™¤äº†ã€‘åŸå…ˆè¿™é‡Œçš„ policy.infer å’Œ robot.move_to_start
            # åŸå› ï¼šæ¨¡å‹è¾“å‡ºçš„æ˜¯ç›¸å¯¹å¢é‡ï¼Œä¸èƒ½ç›´æ¥ç”¨äº move_to_start çš„ç»å¯¹ä½ç½®æ§åˆ¶
            
            # 4. AI æ§åˆ¶å¾ªç¯
            print(">>> AI Loop running... Press 'o' to ABORT (Mark as Fail).")
            aborted = False
            # ç¬¬1æ¬¡è¿è¡Œéœ€è¦ç¼–è¯‘æ¨¡å‹(JIT)ï¼Œç»™ 120ç§’ï¼Œåç»­ç»™ 27ç§’
            current_timeout_limit = 120.0 if episode == 1 else 27.0
            # è®¡æ—¶å™¨åˆå§‹åŒ–
            episode_start_time = time.time()
            consecutive_re_inference_count = 0
            MAX_RETRY = 10 # å¢åŠ é‡è¯•æ¬¡æ•°ï¼Œå› ä¸ºç°åœ¨æœ‰å›æ‹‰æœºåˆ¶ï¼Œæ›´å®¹æ˜“æ•‘å›æ¥
            close_gripper_time = time.time()
            
            if robot.arm.mode != 1:
                print(">>> robot.arm.mode != 1 , enter recover_from_error()")
                robot.recover_from_error(target_mode=1)
            while True:
                # ã€æ–°å¢ã€‘é‡ç½®æœ¬è½®å¼€å§‹æ—¶é—´
                #  æé€Ÿæ£€æŸ¥é€€å‡ºï¼Œä¸è¦ç”¨ select é˜»å¡
                if kb.get_and_clear_key() == 'o':
                    aborted = True; break
                elif kb.get_and_clear_key() == 'p':
                    if not pause_requested:
                        print("\n>>> â³ [æŒ‡ä»¤æ”¶åˆ°] æœ¬è½®ç»“æŸåå°†æš‚åœ...")
                        pause_requested = True
                elif kb.get_and_clear_key() == 'y':
                    print("\n>>> ğŸ¯ [æŒ‡ä»¤æ”¶åˆ°] æ‰‹åŠ¨è§¦å‘æŠ“å– (Mark as Success).")
                    # ç«‹å³é—­åˆå¤¹çˆª (æ¨¡æ‹Ÿæ¨¡å‹è¾“å‡ºäº†é—­åˆ)
                    robot.close_gripper()
                    time.sleep(0.5) # ç»™ä¸€ç‚¹æ—¶é—´é—­åˆ
                    # æ ‡è®°ä¸ºæˆåŠŸé€€å‡º (ä¸è®¾aborted)
                    # è®°å½•å¤¹çˆªé—­åˆæ—¶é—´ (ç”¨äºè®¡ç®—è€—æ—¶)
                    close_gripper_time = time.time()
                    # è·³å‡ºæ¨ç†å¾ªç¯ï¼Œç›´æ¥è¿›ç»“ç®—
                    break 
                
                # 1. è§‚æµ‹ (Code A: get_observation)
                raw_obs = robot.get_observation()
                # =================================================================
                # ã€DEBUGã€‘å¦‚æœæ˜¯å›æ‹‰ååˆšå›æ¥çš„ç¬¬ä¸€å¸§ï¼Œç«‹åˆ»ä¿å­˜ï¼Œçœ‹çœ‹åˆ°åº•å–‚ç»™äº†æ¨¡å‹ä»€ä¹ˆ
                # =================================================================
                if just_recovered:
                    debug_rec_dir = os.path.join(VIS_SAVE_DIR, "debug_recovery_check")
                    os.makedirs(debug_rec_dir, exist_ok=True)
                    timestamp = int(time.time() * 1000)
                    save_path = os.path.join(debug_rec_dir, f"recovery_input_{timestamp}.jpg")
                    
                    print(f"\n[DEBUG CHECK] æ­£åœ¨ä¿å­˜å›æ‹‰åçš„é¦–å¸§æ¨ç†å›¾åƒ: {save_path}")
                    if 'cam_left_wrist' in raw_obs:
                        # æ³¨æ„ï¼šraw_obs æ˜¯ RGBï¼Œä¿å­˜éœ€è½¬ BGR
                        cv2.imwrite(save_path, cv2.cvtColor(raw_obs['cam_left_wrist'], cv2.COLOR_RGB2BGR))
                    
                    # å­˜å®Œåé‡ç½®æ ‡å¿—ä½ï¼Œåªå­˜è¿™ä¸€å¼ 
                    just_recovered = False
                # =================================================================
                curr_pose_abs = robot.get_current_cartesian() # å½“å‰ç»å¯¹åæ ‡
                
                # æ„é€ ç›¸å¯¹è¾“å…¥ State
                # State = å½“å‰ç»å¯¹ - èµ·å§‹ç»å¯¹
                def normalize_angle(angle):
                    # å°†è§’åº¦æ˜ å°„åˆ° -pi åˆ° pi
                    return (angle + np.pi) % (2 * np.pi) - np.pi
                rel_pose = curr_pose_abs - start_pose_abs
                rel_pose[5] = normalize_angle(curr_pose_abs[5] - start_pose_abs[5])
                print(f"\r[State] Rel_pose: {rel_pose[:3]}", end="") 
                
                # æ‹¼è£… (7ç»´)
                input_state = np.append(rel_pose, robot.current_gripper_state)
                
                # 2. æ¨ç†
                result = policy.infer({
                    "cam_left_wrist": raw_obs["cam_left_wrist"],
                    "cam_right_wrist": raw_obs["cam_right_wrist"],
                    "state": input_state, "prompt": TASK_PROMOT
                })
                
                # æ¨¡å‹è¾“å‡ºçš„æ˜¯ Delta Action Chunk [T, 7]
                action_chunk = np.array(result["actions"])
                
                debugger.update(raw_obs, action_chunk, robot.arm)
                
                # 3. æŠ“å–æ£€æµ‹
                if np.any(action_chunk[:1, 6] > 0.8):
                    close_gripper_time = time.time() # ã€å…³é”®ã€‘è‡ªåŠ¨æŠ“å–ä¹Ÿè¦è®°å½•æ—¶é—´
                    print(">>> Auto Grasp Detected.")
                    break
                
                # 4. æ‰§è¡Œ (å®Œå…¨ä¸€è‡´çš„å¾ªç¯ç»“æ„)
                steps_to_run = min(EXECUTE_STEPS, len(action_chunk))
                # for i in range(steps_to_run):
                #     step_start = time.time()
                    
                #     # å†æ¬¡æé€Ÿæ£€æŸ¥åœæ­¢
                #     if kb.get_and_clear_key() == 'o': 
                #         aborted = True; break
                    
                #     # æ‰§è¡ŒåŠ¨ä½œ (æ³¨æ„ï¼šexecute_action å¿…é¡»æ˜¯ä½ ä¿®æ”¹è¿‡çš„æ”¯æŒ Delta çš„ç‰ˆæœ¬)
                #     robot.execute_action(action_chunk[i])
                    
                #     # é¢‘ç‡æ§åˆ¶ (Code A é€»è¾‘)
                #     elapsed = time.time() - step_start
                #     sleep_time = (1.0 / CONTROL_FREQ) - elapsed
                #     if sleep_time > 0: time.sleep(sleep_time)
                need_re_inference = False
                for i in range(steps_to_run):
                    current_duration = time.time() - episode_start_time
                    if current_duration > episode_start_time:
                        print(f"\n[Timeout] è€—æ—¶ {current_duration:.1f}s > 27s. å¼ºåˆ¶ä¸­æ–­ Chunkï¼Œé‡æ–°æ¨ç†...")
                        aborted = True
                        break # è·³å‡º for å¾ªç¯ -> è¿›å…¥ä¸‹ä¸€æ¬¡ while True (é‡æ–°æ‹ç…§æ¨ç†)

                    raw_action = action_chunk[i]
                    
                    # ã€ä¿®æ”¹é€»è¾‘ã€‘ï¼šå¦‚æœæ¨¡å‹è¾“å‡ºçš„æ˜¯ "ç›¸å¯¹äºStartçš„ä½ç½®"
                    # Target = Start_Pose + Model_Output
                    # æˆ‘ä»¬éœ€è¦ç®—å‡ºå®ƒç›¸å¯¹äº Current çš„ Delta ä¼ ç»™ execute_action
                    
                    # é¢„æµ‹çš„ç›®æ ‡ç»å¯¹ä½ç½®
                    pred_target_abs = start_pose_abs[:6] + raw_action[:6]
                    
                    # è½¬æ¢æˆ mm è¿›è¡Œæ£€æµ‹
                    # =======================================================
                    pred_target_mm = pred_target_abs * 1000.0
                    
                    # ä½¿ç”¨å®½æ¾è¾¹ç•Œ (EXPANDED) è¿›è¡Œæ£€æŸ¥
                    if not robot.is_in_boundary(pred_target_mm, BOUNDARY_EXPANDED):
                        print(f"\n[Safety] ç›®æ ‡ ({pred_target_mm[0]:.0f}, {pred_target_mm[1]:.0f}) è¶…å‡ºå®½æ¾è¾¹ç•Œï¼æ­£åœ¨å›æ‹‰...")
                        # =======================================================
                        # ã€DEBUG æ–°å¢ã€‘: ä¿å­˜å½“å‰å¸§åŠåç»­ç¼“å†²å¸§ï¼ŒéªŒè¯æ˜¯å¦æœ‰å»¶è¿Ÿ
                        # =======================================================
                        debug_dir = os.path.join(VIS_SAVE_DIR, "debug_pullback")
                        os.makedirs(debug_dir, exist_ok=True)
                        timestamp = int(time.time() * 1000)
                        
                        print(f"[Debug] æ­£åœ¨ä¿å­˜å¼‚å¸¸æ—¶åˆ»å›¾åƒåˆ°: {debug_dir}")
                        # 1. ä¿å­˜å¯¼è‡´è¿™æ¬¡é”™è¯¯æ¨ç†çš„â€œæ¡ˆå‘ç°åœºâ€å›¾ç‰‡ (raw_obs)
                        # æ³¨æ„ï¼šraw_obs æ˜¯ RGBï¼ŒOpenCV ä¿å­˜éœ€è¦è½¬ BGR
                        if 'cam_left_wrist' in raw_obs:
                            cv2.imwrite(
                                os.path.join(debug_dir, f"{timestamp}_00_inference_input.jpg"), 
                                cv2.cvtColor(raw_obs['cam_left_wrist'], cv2.COLOR_RGB2BGR)
                            )
                        
                        # 2. è¿ç»­è¯»å–å¹¶ä¿å­˜æ¥ä¸‹æ¥çš„ 5 å¸§ï¼Œçœ‹çœ‹ç¼“å†²åŒºé‡Œæ˜¯ä»€ä¹ˆ
                        # å¦‚æœè¿™ 5 å¼ å›¾å˜åŒ–å·¨å¤§ï¼Œæˆ–è€…ç¬¬ 1 å¼ å’Œç¬¬ 5 å¼ ä½ç½®å·®å¼‚å¾ˆå¤§ï¼Œè¯´æ˜ç¼“å†²åŒºæœ‰ä¸¥é‡ç§¯å‹
                        for i in range(1, 6):
                            temp_obs = robot.get_observation() # è¿™é‡Œé¢åŒ…å«äº†ä¸€æ¬¡ read()
                            if 'cam_left_wrist' in temp_obs:
                                cv2.imwrite(
                                    os.path.join(debug_dir, f"{timestamp}_{i:02d}_buffer_flush.jpg"), 
                                    cv2.cvtColor(temp_obs['cam_left_wrist'], cv2.COLOR_RGB2BGR)
                                )
                            # ç¨å¾® sleep ä¸€ç‚¹ç‚¹ï¼Œæ¨¡æ‹Ÿå¤„ç†æ—¶é—´ï¼Œæˆ–è€…å…¨é€Ÿè¯»ä»¥æµ‹è¯•çº¯ I/O å †ç§¯
                            time.sleep(0.01) 
                        # =======================================================
                        
                        # --- è®¡ç®—å›æ‹‰å‘é‡ ---
                        # ç­–ç•¥ï¼šå‘åŒºåŸŸä¸­å¿ƒç‚¹å›æ‹‰
                        center_pt = np.mean(BOUNDARY_POINTS_2D, axis=0) # åŸå§‹ä¸¥æ ¼è¾¹ç•Œçš„ä¸­å¿ƒ
                        curr_xy = pred_target_mm[:2]
                        
                        # è®¡ç®—æ–¹å‘å‘é‡: Current -> Center
                        vec_to_center = center_pt - curr_xy
                        norm = np.linalg.norm(vec_to_center)
                        
                        if norm > 0:
                            # å½’ä¸€åŒ–å¹¶ä¹˜ä»¥å›æ‹‰è·ç¦» (ä¾‹å¦‚ 50mm)
                            # pull_back_vec = (vec_to_center / norm) * 50.0
                            pull_back_vec = (vec_to_center / norm) * 50.0
                        else:
                            pull_back_vec = np.array([10.0, 10.0]) # å¼‚å¸¸ä¿æŠ¤
                            
                        # --- æ‰§è¡Œå›æ‹‰åŠ¨ä½œ ---
                        # è·å–å½“å‰ä½ç½®
                        curr_pose_recover = robot.get_current_cartesian()
                        # ç›®æ ‡ä½ç½® = å½“å‰ä½ç½® + å›æ‹‰å‘é‡ (æ³¨æ„å•ä½æ¢ç®— mm -> m)
                        target_pose_recover = curr_pose_recover.copy()
                        target_pose_recover[0] += pull_back_vec[0] / 1000.0
                        target_pose_recover[1] += pull_back_vec[1] / 1000.0
                        # Zè½´ä¿æŒä¸å˜æˆ–ç¨å¾®æŠ¬é«˜ä¸€ç‚¹ç‚¹é˜²æ­¢æ‹–æ‹½
                        # target_pose_recover[2] += 0.01 
                        
                        # è®¡ç®— Delta å¹¶æ‰§è¡Œ
                        delta_recover = target_pose_recover - curr_pose_recover
                        # æ‹¼è£… Action (å¤¹çˆªä¿æŒå½“å‰çŠ¶æ€)
                        action_recover = np.append(delta_recover[:6], robot.current_gripper_state)
                        
                        print(f"[Recovery] æ‰§è¡Œå›æ‹‰åŠ¨ä½œ: dX={pull_back_vec[0]:.1f}mm, dY={pull_back_vec[1]:.1f}mm")
                        robot.execute_action(action_recover)
                        # =======================================================
                        # å›æ‹‰åï¼šæ¸…ç†ç›¸æœºç¼“å­˜ + åŸåœ°åœç•™ 2 ç§’ï¼Œå†å¼€å§‹ä¸‹ä¸€æ¬¡æ¨ç†
                        # ç›®çš„ï¼šå°½é‡æ¨¡æ‹Ÿ episode å¼€å§‹æ—¶çš„ "flush + ç¨³å®šä¸€ä¸‹" çš„è§‚æµ‹æ¡ä»¶
                        # =======================================================
                        try:
                            print("[Recovery] å›æ‹‰å®Œæˆï¼šæ¸…ç†ç›¸æœºç¼“å­˜ï¼Œå¹¶åŸåœ°ç­‰å¾… 2 ç§’åé‡æ–°æ¨ç†...")
                            robot.flush_cameras()
                            time.sleep(2.0)
                            robot.flush_cameras()
                        except Exception as e:
                            print(f"[Recovery] ç›¸æœº flush/ç­‰å¾…è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼ˆå¿½ç•¥ç»§ç»­ï¼‰ï¼š{e}")
                        
                        # =======================================================
                        # ã€å…³é”®ä¿®å¤ã€‘å›æ‹‰åé‡ç½® start_pose_abs ä¸ºå½“å‰å›æ‹‰åçš„ä½ç½®
                        # åŸå› ï¼šæ¨¡å‹è¾“å‡ºçš„ action æ˜¯"ç›¸å¯¹ start_pose_abs çš„ç›®æ ‡ä½ç½®"
                        # å¦‚æœå›æ‹‰åä¸é‡ç½®ï¼Œåæ ‡ç³»ä¼šé”™ä¹±ï¼Œå¯¼è‡´æœé”™è¯¯æ–¹å‘è¿åŠ¨
                        # =======================================================
                        new_start_pose = robot.get_current_cartesian()
                        if new_start_pose is not None:
                            print(f"[Recovery] é‡ç½® episode èµ·ç‚¹ï¼šä» {np.round(start_pose_abs[:3]*1000, 1)} æ›´æ–°ä¸º {np.round(new_start_pose[:3]*1000, 1)} (mm)")
                            start_pose_abs = new_start_pose
                        else:
                            print("[Recovery] âš ï¸ è­¦å‘Šï¼šæ— æ³•è·å–å›æ‹‰åä½ç½®ï¼Œstart_pose_abs æœªæ›´æ–°")
                        
                        # å¼ºåˆ¶è§¦å‘é‡æ¨ç†
                        need_re_inference = True
                        # æ ‡è®°ï¼šåˆšæ‰å‘ç”Ÿäº†å›æ‹‰ï¼Œä¸‹ä¸€æ¬¡å¾ªç¯å¼€å¤´è¦æŸ¥å›¾
                        just_recovered = True 
                        break 
                    # =======================================================
                
                    # å½“å‰ç»å¯¹ä½ç½®
                    curr_pose_abs = robot.get_current_cartesian()
                    
                    # è®¡ç®—éœ€è¦çš„ Delta
                    real_delta = pred_target_abs - curr_pose_abs
                    
                    # æ‹¼è£…å¤¹çˆª
                    action_to_execute = np.append(real_delta, raw_action[6])
                    
                    success = robot.execute_action(action_to_execute) # execute_action å†…éƒ¨ä¼šé™å¹…
                    if not success:
                        print("\n[Safety] åŠ¨ä½œæ‰§è¡Œå¤±è´¥ (å…³èŠ‚è·³å˜/IK)ã€‚å¯åŠ¨ã€ä¸»åŠ¨æ¢å¤ã€‘ç­–ç•¥...")
                        
                        # --- 1. è®¡ç®—æ¢å¤å‘é‡ (å‘ä¸­å¿ƒå›æ‹‰ + å‘ä¸ŠæŠ¬èµ·) ---
                        # è·å–å½“å‰ä½ç½® (ç±³)
                        curr_pose_m = robot.get_current_cartesian()
                        curr_xy_mm = curr_pose_m[:2] * 1000.0
                        
                        # è®¡ç®—ä¸­å¿ƒç‚¹ (mm)
                        center_pt = np.mean(BOUNDARY_POINTS_2D, axis=0)
                        
                        # è®¡ç®—æŒ‡å‘ä¸­å¿ƒçš„æ–¹å‘
                        vec_to_center = center_pt - curr_xy_mm
                        dist_to_center = np.linalg.norm(vec_to_center)
                        
                        # æ„é€ æ¢å¤åŠ¨ä½œ Delta (å•ä½: ç±³)
                        # æ ¼å¼: [dx, dy, dz, dr, dp, dy, gripper]
                        recovery_delta = np.zeros(7)
                        
                        # A. XYå¹³é¢çš„å›æ‹‰ (å›æ‹‰ 30mm)
                        if dist_to_center > 0:
                            direction = vec_to_center / dist_to_center
                            # å¾€ä¸­å¿ƒæ‹‰ 0.03ç±³
                            recovery_delta[0] = direction[0] * 0.03 
                            recovery_delta[1] = direction[1] * 0.03
                        
                        # B. Zè½´çš„æŠ¬å‡ (æŠ¬èµ· 20mm) - è¿™ä¸€æ­¥å¯¹è§£å†³å…³èŠ‚è·³å˜éå¸¸æœ‰æ•ˆ
                        recovery_delta[2] = 0.02 
                        
                        # C. ä¿æŒå¤¹çˆªçŠ¶æ€ä¸å˜
                        recovery_delta[6] = robot.current_gripper_state
                        
                        print(f"[Recovery] æ‰§è¡Œé¿é™©åŠ¨ä½œ: å‘ä¸­å¿ƒå›æ‹‰ 3cm, å‘ä¸ŠæŠ¬èµ· 2cm...")
                        
                        # --- 2. æ‰§è¡Œæ¢å¤åŠ¨ä½œ ---
                        # å†æ¬¡è°ƒç”¨ execute_action æ‰§è¡Œè¿™ä¸ªäººå·¥ç”Ÿæˆçš„åŠ¨ä½œ
                        # å¦‚æœè¿™æ¬¡è¿˜å¤±è´¥ï¼Œé‚£å°±æ²¡åŠæ³•äº†ï¼Œåªèƒ½äº¤ç»™å¤–å±‚çš„ MAX_RETRY å»å¤„ç†
                        rec_success = robot.execute_action(recovery_delta)
                        
                        if rec_success:
                            print("[Recovery] é¿é™©åŠ¨ä½œæ‰§è¡ŒæˆåŠŸã€‚é‡æ–°å¼€å§‹æ¨ç†ã€‚")
                            # =======================================================
                            # ã€å…³é”®ä¿®å¤ã€‘é¿é™©åŠ¨ä½œåä¹Ÿé‡ç½® start_pose_abs
                            # åŸå› ï¼šæœºæ¢°è‡‚ä½ç½®å·²æ”¹å˜ï¼Œéœ€è¦æ›´æ–°åæ ‡ç³»åŸç‚¹
                            # =======================================================
                            new_start_pose = robot.get_current_cartesian()
                            if new_start_pose is not None:
                                print(f"[Recovery] é‡ç½® episode èµ·ç‚¹ï¼šä» {start_pose_abs[:3]*1000:.1f} æ›´æ–°ä¸º {new_start_pose[:3]*1000:.1f} (mm)")
                                start_pose_abs = new_start_pose
                        else:
                            print("[Recovery] é¿é™©åŠ¨ä½œä¹Ÿå¤±è´¥äº† (å¯èƒ½å¡æ­»)ã€‚")
                        
                        # æ— è®ºé¿é™©æ˜¯å¦æˆåŠŸï¼Œéƒ½å¿…é¡»ä¸­æ–­å½“å‰ Chunkï¼Œé‡æ–°æ‹ç…§æ¨ç†
                        need_re_inference = True
                        break
                    else:
                        close_gripper_time = time.time()
                
                    key = kb.get_and_clear_key()
                    if key == 'o': 
                        aborted = True
                        break
                    elif key == 'p':
                        if not pause_requested:
                            print("\n>>> â³ [æŒ‡ä»¤æ”¶åˆ°] æœ¬è½®ç»“æŸåå°†æš‚åœ...")
                            pause_requested = True
                    elif key == 'y':
                        print("\n>>> ğŸ¯ [æŒ‡ä»¤æ”¶åˆ°] æ‰‹åŠ¨è§¦å‘æŠ“å– (Mark as Success).")
                        robot.close_gripper()
                        close_gripper_time = time.time()
                        aborted = False
                        # è¿™é‡Œéœ€è¦åŒé‡ breakï¼Œå…ˆè®¾ç½®æ ‡å¿—ä½
                        break 
                    # è®°å½•æ¯ä¸€æ­¥çš„å®é™…ä½ç½®
                    # ç¡®ä¿ execute_action ä¹‹åæœºæ¢°è‡‚å·²ç»åŠ¨äº†
                    curr_pos_abs = robot.get_current_cartesian()
                    recorder.step(curr_pos_abs)
                
                if aborted: break
                if key == 'y':
                    break
                # å¦‚æœæ˜¯å› ä¸ºè§¦å‘äº†ä¸Šè¿°ä¸‰ä¸ªä¿æŠ¤æœºåˆ¶è€Œ break çš„
                if need_re_inference:
                    consecutive_re_inference_count += 1
                    if consecutive_re_inference_count >= MAX_RETRY:
                        print(f"\n[Failure] è¿ç»­ {MAX_RETRY} æ¬¡é‡æ¨ç†/å›æ‹‰æ— æ•ˆã€‚åˆ¤å®šå¤±è´¥ã€‚")
                        aborted = True
                        break
                    continue
                else:
                    consecutive_re_inference_count = 0
            
            # 5. ç»“ç®—ç¯èŠ‚
            if aborted:
                print("\n>>> Inference Aborted by 'o'. Marking as FAILURE.")
                viz.update_result(target_pose, False) # è®°ä¸ºå¤±è´¥
                robot.open_gripper()
                target_up = list(target_pose); target_up[2] += 100
                robot.arm.set_mode(0); robot.arm.set_state(0)
                robot.arm.set_position(*target_up, speed=300, wait=True, is_radian=True)
                target_pose_withObjetcZ = list(target_pose);target_up[2] = OBJECT_Z
                robot.arm.set_position(*target_pose_withObjetcZ, speed=300, wait=True, is_radian=True)
                robot.close_gripper(); time.sleep(2.0)
                robot.arm.set_position(*target_up, speed=300, wait=True, is_radian=True)
                
                current_metrics = recorder.end_episode(success=False, close_gripper_time = close_gripper_time)
                robot.arm.set_position(*HOME_POS, speed=300, wait=True, is_radian=True)

            else:
                # æ­£å¸¸ç»“æŸï¼Œç­‰å¾…äººå·¥åˆ¤å®š
                robot.close_gripper()
                time.sleep(2.0)
                current_metrics = recorder.end_episode(success=True, close_gripper_time = close_gripper_time)
                robot.move_home_scripted()
                print(">>> Marked as SUCCESS.")
                viz.update_result(target_pose, True)
                
                print("\n>>> Evaluate Result: [y] Success / [n] Failure")
                # å¾ªç¯ç­‰å¾…ç›´åˆ°æŒ‰ä¸‹ y æˆ– n
                # while True:
                #     k = kb.get_and_clear_key()
                    
                #     if k == 'y': 
                #         print(">>> Marked as SUCCESS.")
                #         current_metrics = recorder.end_episode(success=True, close_gripper_time = close_gripper_time)
                #         robot.arm.set_mode(0)
                #         robot.arm.set_state(0)
                #         time.sleep(0.1) # ç­‰å¾…å›ºä»¶åˆ‡æ¢å®Œæˆ
                #         target_up = list(target_pose); target_up[2] += 100
                #         robot.arm.set_position(*target_up, speed=100, wait=True, is_radian=True)
                #         robot.move_home_scripted()
                #         viz.update_result(target_pose, True)
                #         break
                #     elif k == 'n': 
                #         print(">>> Marked as FAILURE.")
                #         current_metrics = recorder.end_episode(success=False, close_gripper_time = close_gripper_time)
                #         robot.arm.set_mode(0)
                #         robot.arm.set_state(0)
                #         time.sleep(0.1) # ç­‰å¾…å›ºä»¶åˆ‡æ¢å®Œæˆ
                #         robot.open_gripper(); time.sleep(1.0)
                #         target_up = list(target_pose); target_up[2] += 100

                #         robot.arm.set_position(*target_up, speed=300, wait=True, is_radian=True)
                #         robot.arm.set_position(*target_pose, speed=300, wait=True, is_radian=True)
                #         robot.close_gripper(); time.sleep(2.0)
                #         robot.arm.set_position(*target_up, speed=300, wait=True, is_radian=True)
                
                #         robot.arm.set_position(*target_up, speed=100, wait=True, is_radian=True)
                #         robot.move_home_scripted()
                #         viz.update_result(target_pose, False)
                #         break
                #     time.sleep(0.05)
            
            # ã€æ–°å¢ã€‘å…³é”®æ­¥éª¤ï¼šæµ‹è¯•ç»“æŸï¼ˆæ— è®ºæˆåŠŸå¤±è´¥ï¼‰ï¼Œæ ‡è®°ä¸ºå®Œæˆå¹¶ä¿å­˜è¿›åº¦
            sampler.mark_current_done()   
            recorder.print_current_metrics(current_metrics)
            recorder.print_summary()
            
            if pause_requested:
                print("\n" + "="*50)
                print(">>> â¸ï¸  ç¨‹åºå·²æš‚åœ (ç”¨æˆ·è¯·æ±‚)ã€‚")
                print(">>> âŒ¨ï¸  è¯·æŒ‰ [ENTER] é”®ç»§ç»­ä¸‹ä¸€è½®æµ‹è¯•...")
                print("="*50)
                
                # å¾ªç¯ç­‰å¾…å›è½¦
                while True:
                    k = kb.get_and_clear_key()
                    if k == '\n' or k == '\r': # å›è½¦é”®
                        print(">>> â–¶ï¸  ç»§ç»­è¿è¡Œ...")
                        pause_requested = False # é‡ç½®æ ‡å¿—ä½
                        break
                    time.sleep(0.1)

    except KeyboardInterrupt:
        print("Stopped.")
        recorder.print_summary()
    finally:
        kb.stop()
        robot.close()

if __name__ == "__main__":
    main()